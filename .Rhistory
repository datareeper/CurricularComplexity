DocumentTermMatrix(corpus, control = list(weighting = weightTfIdf)) -> dtm.tfidf
dtm.df <- as.matrix(dtm.tfidf)
similarity <- matrix(NA, nrow=nrow(dtm.df), ncol=nrow(dtm.df))
index2 <- 1
for (index1 in 1:nrow(dtm.df))
{
while (index2 < nrow(dtm.df))
{
similarity[index1,index2] <- cosinesim(dtm.df[index2,],dtm.df[index1,])
index2 <- index2 + 1
}
index2 <- 1
}
dissimilarity <- as.dist(1-similarity)
clustering <- hclust(dissimilarity, method = "ward.D2", members = NULL)
plot(clustering, labels = FALSE)
groups <- cutree(clustering,h = 1.97)  # 2.075
abline(h = 1.965)
coded$Cluster <- groups
summary.codes <- matrix(0, nrow = 7, ncol = 5)
index <- 1
while (index <= 7)
{
rows <- which(coded$Cluster==index)
perc <- unname(colSums(coded[rows,4:8])/length(rows))
summary.codes[index,] <- perc
index <- index + 1
}
summary.codes <- as.data.frame(summary.codes)
names(summary.codes) <- c("Preparedness","Practice","Helped","Growth","Barriers")
cosinesim <- function(x,y)
{
x <- as.matrix(x)
y <- as.matrix(y)
z <- matrix(data = NA, nrow = length(x))
for (index in 1:length(x))
{
z[index] <- x[index]*y[index]
}
lengthx <- sqrt(sum(x^2))
lengthy <- sqrt(sum(y^2))
measure <- sum(z)/(lengthx*lengthy)
measure <- ifelse(is.nan(measure),0.00,measure)
measure <- as.numeric(format(round(measure, 2), nsmall = 2))
return(measure)
}
index2 <- 1
for (index1 in 1:nrow(dtm.df))
{
while (index2 < nrow(dtm.df))
{
similarity[index1,index2] <- cosinesim(dtm.df[index2,],dtm.df[index1,])
index2 <- index2 + 1
}
index2 <- 1
}
dissimilarity <- as.dist(1-similarity)
clustering <- hclust(dissimilarity, method = "ward.D2", members = NULL)
plot(clustering, labels = FALSE)
groups <- cutree(clustering,h = 1.97)  # 2.075
abline(h = 1.965)
coded$Cluster <- groups
summary.codes <- matrix(0, nrow = 7, ncol = 5)
index <- 1
while (index <= 7)
{
rows <- which(coded$Cluster==index)
perc <- unname(colSums(coded[rows,4:8])/length(rows))
summary.codes[index,] <- perc
index <- index + 1
}
summary.codes <- as.data.frame(summary.codes)
names(summary.codes) <- c("Preparedness","Practice","Helped","Growth","Barriers")
group1 <- filter(coded, Cluster == 1)
group2 <- filter(coded, Cluster == 2)
group3 <- filter(coded, Cluster == 3)
group4 <- filter(coded, Cluster == 4)
group5 <- filter(coded, Cluster == 5)
group6 <- filter(coded, Cluster == 6)
group7 <- filter(coded, Cluster == 7)
summary.codes
coded$Cluster
coded <- data
uncoded <- which(rowSums(data[,4:8])==0)
coded <- coded[-uncoded,]
data$Text <- str_replace(data$Text,"?","")
data$Text <- str_replace(data$Text,"?","")
data$Text <- str_replace(data$Text,"?","")
sum(str_count(data$Text, "?"))
corpus <- SimpleCorpus(VectorSource(coded$Text))
# 1. Stripping any extra white space:
corpus <- tm_map(corpus, stripWhitespace)
# 2. Transforming everything to lowercase
corpus <- tm_map(corpus, content_transformer(tolower))
# 3. Stem documents
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(corpus)
DocumentTermMatrix(corpus, control = list(weighting = weightTfIdf)) -> dtm.tfidf
dtm.df <- as.matrix(dtm.tfidf)
similarity <- matrix(NA, nrow=nrow(dtm.df), ncol=nrow(dtm.df))
index2 <- 1
for (index1 in 1:nrow(dtm.df))
{
while (index2 < nrow(dtm.df))
{
similarity[index1,index2] <- cosinesim(dtm.df[index2,],dtm.df[index1,])
index2 <- index2 + 1
}
index2 <- 1
}
dissimilarity <- as.dist(1-similarity)
clustering <- hclust(dissimilarity, method = "ward.D2", members = NULL)
plot(clustering, labels = FALSE)
groups <- cutree(clustering,h = 1.97)  # 2.075
abline(h = 1.965)
coded$Cluster <- groups
summary.codes <- matrix(0, nrow = 7, ncol = 5)
index <- 1
while (index <= 7)
{
rows <- which(coded$Cluster==index)
perc <- unname(colSums(coded[rows,4:8])/length(rows))
summary.codes[index,] <- perc
index <- index + 1
}
summary.codes <- as.data.frame(summary.codes)
names(summary.codes) <- c("Preparedness","Practice","Helped","Growth","Barriers")
group1 <- filter(coded, Cluster == 1)
group2 <- filter(coded, Cluster == 2)
group3 <- filter(coded, Cluster == 3)
group4 <- filter(coded, Cluster == 4)
group5 <- filter(coded, Cluster == 5)
group6 <- filter(coded, Cluster == 6)
group7 <- filter(coded, Cluster == 7)
summary.codes
coded$Cluster
coded <- data
uncoded <- which(rowSums(data[,4:8])==0)
coded <- coded[-uncoded,]
View(coded)
View(coded)
View(coded)
View(coded)
View(data)
sum(str_count(data$Text, "?"))
library(dplyr)
library(klaR)
library(tm)
library(SnowballC)
library(stringr)
library(knitr)
library(irrCAC)
sum(str_count(data$Text, "?"))
View(coded)
data$Text <- str_replace(data$Text,"?","")
View(data)
View(coded)
View(data)
View(coded)
View(data)
data <- read.csv("C:/Users/reepi/Dropbox/Articles/Med Ed/Goal Orientation Data.csv", stringsAsFactors = FALSE)
data <- data[-1,1:9]
data[is.na(data) == TRUE] <- 0
data <- data[,-3]
names(data) <- c("Text", "Group", "Preparedness","Practice","Helped","Growth","Barriers","Experience")
View(data)
counts <- colSums(data[,4:8])
data$Text <- str_replace(data$Text,"  ","")
View(data)
data <- read.csv("C:/Users/reepi/Dropbox/Articles/Med Ed/Goal Orientation Data.csv", stringsAsFactors = FALSE)
data <- data[-1,1:9]
data[is.na(data) == TRUE] <- 0
data <- data[,-3]
names(data) <- c("Text", "Group", "Preparedness","Practice","Helped","Growth","Barriers","Experience")
cosinesim <- function(x,y)
{
x <- as.matrix(x)
y <- as.matrix(y)
z <- matrix(data = NA, nrow = length(x))
for (index in 1:length(x))
{
z[index] <- x[index]*y[index]
}
lengthx <- sqrt(sum(x^2))
lengthy <- sqrt(sum(y^2))
measure <- sum(z)/(lengthx*lengthy)
measure <- ifelse(is.nan(measure),0.00,measure)
measure <- as.numeric(format(round(measure, 2), nsmall = 2))
return(measure)
}
coded <- data
uncoded <- which(rowSums(data[,4:8])==0)
coded <- coded[-uncoded,]
corpus <- SimpleCorpus(VectorSource(coded$Text))
# 1. Stripping any extra white space:
corpus <- tm_map(corpus, stripWhitespace)
# 2. Transforming everything to lowercase
corpus <- tm_map(corpus, content_transformer(tolower))
# 3. Stem documents
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(corpus)
DocumentTermMatrix(corpus, control = list(weighting = weightTfIdf)) -> dtm.tfidf
dtm.df <- as.matrix(dtm.tfidf)
similarity <- matrix(NA, nrow=nrow(dtm.df), ncol=nrow(dtm.df))
index2 <- 1
for (index1 in 1:nrow(dtm.df))
{
while (index2 < nrow(dtm.df))
{
similarity[index1,index2] <- cosinesim(dtm.df[index2,],dtm.df[index1,])
index2 <- index2 + 1
}
index2 <- 1
}
dissimilarity <- as.dist(1-similarity)
clustering <- hclust(dissimilarity, method = "ward.D2", members = NULL)
plot(clustering, labels = FALSE)
groups <- cutree(clustering,h = 1.97)  # 2.075
abline(h = 1.965)
coded$Cluster <- groups
summary.codes <- matrix(0, nrow = 7, ncol = 5)
index <- 1
while (index <= 7)
{
rows <- which(coded$Cluster==index)
perc <- unname(colSums(coded[rows,4:8])/length(rows))
summary.codes[index,] <- perc
index <- index + 1
}
summary.codes <- as.data.frame(summary.codes)
names(summary.codes) <- c("Preparedness","Practice","Helped","Growth","Barriers")
data <- read.csv("C:/Users/reepi/Dropbox/Articles/Med Ed/Clustered groups for GO.csv", stringsAsFactors = FALSE)
View(data)
View(data)
group1 <- filter(clustered, Cluster == 1)
group2 <- filter(clustered, Cluster == 2)
group3 <- filter(clustered, Cluster == 3)
group4 <- filter(clustered, Cluster == 4)
group5 <- filter(clustered, Cluster == 5)
group6 <- filter(clustered, Cluster == 6)
group7 <- filter(clustered, Cluster == 7)
clustered <- read.csv("C:/Users/reepi/Dropbox/Articles/Med Ed/Clustered groups for GO.csv", stringsAsFactors = FALSE)
group1 <- filter(clustered, Cluster == 1)
group2 <- filter(clustered, Cluster == 2)
group3 <- filter(clustered, Cluster == 3)
group4 <- filter(clustered, Cluster == 4)
group5 <- filter(clustered, Cluster == 5)
group6 <- filter(clustered, Cluster == 6)
group7 <- filter(clustered, Cluster == 7)
View(clustered)
corpus <- SimpleCorpus(VectorSource(clustered$Text))
# 1. Stripping any extra white space:
corpus <- tm_map(corpus, stripWhitespace)
# 2. Transforming everything to lowercase
corpus <- tm_map(corpus, content_transformer(tolower))
# 3. Stem documents
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
?DocumentTermMatrix
DocumentTermMatrix(corpus)
DTM <- DocumentTermMatrix(corpus)
DTM$i
DTM$nrow
dtm.df
DTM <- DocumentTermMatrix(corpus, control = "weightTf")
DTM <- DocumentTermMatrix(corpus, control = list("weightTf"))
DTM <- as.matrix(DTM)
View(DTM)
DTM <- cbind(clustered$Cluster,DTM)
View(DTM)
group1 <- filter(DTM, Cluster == 1)
group2 <- filter(DTM, Cluster == 2)
group3 <- filter(DTM, Cluster == 3)
group4 <- filter(DTM, Cluster == 4)
group5 <- filter(DTM, Cluster == 5)
group6 <- filter(DTM, Cluster == 6)
group7 <- filter(DTM, Cluster == 7)
DTM <- as.data.frame(cbind(clustered$Cluster,DTM))
View(DTM)
DTM <- DocumentTermMatrix(corpus, control = list("weightTf"))
DTM <- as.matrix(DTM)
DTM <- as.data.frame(cbind(clustered$Cluster,DTM))
View(DTM)
names(DTM)[1] <- "Cluster"
View(DTM)
group1 <- filter(DTM, Cluster == 1)
group2 <- filter(DTM, Cluster == 2)
group3 <- filter(DTM, Cluster == 3)
group4 <- filter(DTM, Cluster == 4)
group5 <- filter(DTM, Cluster == 5)
group6 <- filter(DTM, Cluster == 6)
group7 <- filter(DTM, Cluster == 7)
View(group1)
colSum(group1)
colSums(group1)
sort(colSums(group1), decreasing = TRUE)
sort(colSums(group1), decreasing = TRUE)
sort(colSums(group2), decreasing = TRUE)
sort(colSums(group3), decreasing = TRUE)
sort(colSums(group4), decreasing = TRUE)
sort(colSums(group5), decreasing = TRUE)
sort(colSums(group6), decreasing = TRUE)
sort(colSums(group7), decreasing = TRUE)
sort(colSums(group2), decreasing = TRUE)
View(DTM)
stems1 <- sort(colSums(group1), decreasing = TRUE)
names(stem1)
names(stems1)
names(which(stems1 > 15))
names(which(stems1 > 5))
View(DTM)
View(data)
View(DTM)
stems2 <- sort(colSums(group2), decreasing = TRUE)
names(which(stems2 > 5))
stems3 <- sort(colSums(group3), decreasing = TRUE)
names(which(stems3 > 5))
stems4 <- sort(colSums(group4), decreasing = TRUE)
names(which(stems4 > 5))
stems5 <- sort(colSums(group5), decreasing = TRUE)
names(which(stems5 > 5))
stems6 <- sort(colSums(group6), decreasing = TRUE)
names(which(stems6 > 5))
stems7 <- sort(colSums(group7), decreasing = TRUE)
names(which(stems7 > 5))
View(clustered)
data <- read.csv("C:/Users/reepi/Dropbox/Articles/Med Ed/Goal Orientation Data.csv", stringsAsFactors = FALSE)
View(data)
data <- data[-1,1:9]
data[is.na(data) == TRUE] <- 0
data <- data[,-3]
names(data) <- c("Text", "Group", "Preparedness","Practice","Helped","Growth","Barriers","Experience")
View(data)
coded <- data
uncoded <- which(rowSums(data[,4:8])==0)
coded <- coded[-uncoded,]
corpus <- SimpleCorpus(VectorSource(coded$Text))
# 1. Stripping any extra white space:
corpus <- tm_map(corpus, stripWhitespace)
# 2. Transforming everything to lowercase
corpus <- tm_map(corpus, content_transformer(tolower))
# 3. Stem documents
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(corpus)
DocumentTermMatrix(corpus, control = list(weighting = weightTfIdf)) -> dtm.tfidf
dtm.df <- as.matrix(dtm.tfidf)
similarity <- matrix(NA, nrow=nrow(dtm.df), ncol=nrow(dtm.df))
index2 <- 1
for (index1 in 1:nrow(dtm.df))
{
while (index2 < nrow(dtm.df))
{
similarity[index1,index2] <- cosinesim(dtm.df[index2,],dtm.df[index1,])
index2 <- index2 + 1
}
index2 <- 1
}
dissimilarity <- as.dist(1-similarity)
clustering <- hclust(dissimilarity, method = "ward.D2", members = NULL)
plot(clustering, labels = FALSE)
groups <- cutree(clustering,h = 1.97)  # 2.075
corpus <- SimpleCorpus(VectorSource(data$Text))
# 1. Stripping any extra white space:
corpus <- tm_map(corpus, stripWhitespace)
# 2. Transforming everything to lowercase
corpus <- tm_map(corpus, content_transformer(tolower))
# 3. Stem documents
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
DocumentTermMatrix(corpus, control = list(weighting = weightTfIdf)) -> dtm.tfidf
dtm.df <- as.matrix(dtm.tfidf)
similarity <- matrix(NA, nrow=nrow(dtm.df), ncol=nrow(dtm.df))
index2 <- 1
for (index1 in 1:nrow(dtm.df))
{
while (index2 < nrow(dtm.df))
{
similarity[index1,index2] <- cosinesim(dtm.df[index2,],dtm.df[index1,])
index2 <- index2 + 1
}
index2 <- 1
}
dissimilarity <- as.dist(1-similarity)
clustering <- hclust(dissimilarity, method = "ward.D2", members = NULL)
plot(clustering, labels = FALSE)
groups <- cutree(clustering,5)
#Uncoded segs
cosinesim <- function(x,y)
{
x <- as.matrix(x)
y <- as.matrix(y)
z <- matrix(data = NA, nrow = length(x))
for (index in 1:length(x))
{
z[index] <- x[index]*y[index]
}
lengthx <- sqrt(sum(x^2))
lengthy <- sqrt(sum(y^2))
measure <- sum(z)/(lengthx*lengthy)
measure <- ifelse(is.nan(measure),0.00,measure)
measure <- as.numeric(format(round(measure, 2), nsmall = 2))
return(measure)
}
coded <- data
uncoded <- which(rowSums(data[,4:8])==0)
coded <- coded[-uncoded,]
corpus <- SimpleCorpus(VectorSource(coded$Text))
# 1. Stripping any extra white space:
corpus <- tm_map(corpus, stripWhitespace)
# 2. Transforming everything to lowercase
corpus <- tm_map(corpus, content_transformer(tolower))
# 3. Stem documents
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(corpus)
DocumentTermMatrix(corpus, control = list(weighting = weightTfIdf)) -> dtm.tfidf
dtm.df <- as.matrix(dtm.tfidf)
similarity <- matrix(NA, nrow=nrow(dtm.df), ncol=nrow(dtm.df))
index2 <- 1
for (index1 in 1:nrow(dtm.df))
{
while (index2 < nrow(dtm.df))
{
similarity[index1,index2] <- cosinesim(dtm.df[index2,],dtm.df[index1,])
index2 <- index2 + 1
}
index2 <- 1
}
dissimilarity <- as.dist(1-similarity)
clustering <- hclust(dissimilarity, method = "ward.D2", members = NULL)
plot(clustering, labels = FALSE)
groups <- cutree(clustering,h = 1.97)  # 2.075
abline(h = 1.965)
coded$Cluster <- groups
summary.codes <- matrix(0, nrow = 7, ncol = 5)
index <- 1
while (index <= 7)
{
rows <- which(coded$Cluster==index)
perc <- unname(colSums(coded[rows,4:8])/length(rows))
summary.codes[index,] <- perc
index <- index + 1
}
summary.codes <- as.data.frame(summary.codes)
names(summary.codes) <- c("Preparedness","Practice","Helped","Growth","Barriers")
#Uncoded segs
data <- read.csv("C:/Users/reepi/Dropbox/Articles/Med Ed/Clustered groups for GO.csv", stringsAsFactors = FALSE)
View(data)
data <- data[,-9]
View(data)
coded <- data
uncoded <- which(rowSums(data[,4:8])==0)
coded <- data
View(coded)
corpus <- SimpleCorpus(VectorSource(coded$Text))
# 1. Stripping any extra white space:
corpus <- tm_map(corpus, stripWhitespace)
# 2. Transforming everything to lowercase
corpus <- tm_map(corpus, content_transformer(tolower))
# 3. Stem documents
corpus <- tm_map(corpus, stemDocument)
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
dtm <- DocumentTermMatrix(corpus)
DocumentTermMatrix(corpus, control = list(weighting = weightTfIdf)) -> dtm.tfidf
dtm.df <- as.matrix(dtm.tfidf)
similarity <- matrix(NA, nrow=nrow(dtm.df), ncol=nrow(dtm.df))
index2 <- 1
for (index1 in 1:nrow(dtm.df))
{
while (index2 < nrow(dtm.df))
{
similarity[index1,index2] <- cosinesim(dtm.df[index2,],dtm.df[index1,])
index2 <- index2 + 1
}
index2 <- 1
}
dissimilarity <- as.dist(1-similarity)
clustering <- hclust(dissimilarity, method = "ward.D2", members = NULL)
plot(clustering, labels = FALSE)
groups <- cutree(clustering,h = 1.97)  # 2.075
abline(h = 1.965)
coded$Cluster <- groups
summary.codes <- matrix(0, nrow = 7, ncol = 5)
index <- 1
while (index <= 7)
{
rows <- which(coded$Cluster==index)
perc <- unname(colSums(coded[rows,4:8])/length(rows))
summary.codes[index,] <- perc
index <- index + 1
}
summary.codes <- as.data.frame(summary.codes)
names(summary.codes) <- c("Preparedness","Practice","Helped","Growth","Barriers")
View(summary.codes)
View(coded)
